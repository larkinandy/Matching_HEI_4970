{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e1e1b5",
   "metadata": {},
   "source": [
    "# Select Best Matches #\n",
    "**Author:** Andrew Larkin <br>\n",
    "**Date Created:** January 13, 2022 <br>\n",
    "**Summary:** Match residences in the top and bottom quartile of wind exposures.  For each record in the top quartile, a list of nearby exposures in the bottom quartile has already been created.  This script attempts to find the best set of top:bottom quartile matches.  \n",
    "**Note:** for more information on how the lists of nearby exposures was derived, see the python script 'deriveMatchParallel.py'<br>\n",
    "**Note:** for more information on how these matched exposures were further transformed into the final dataset used for the wind epidemiological study, see the jupyter notebook 'collateWindEpiDataset.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099dd4f5",
   "metadata": {},
   "source": [
    "## Part 1: load libraries and define global static variables ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc10000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "import os\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "import gConst as const # contains absolute filepaths.  Hidden so script can be shared without compromising sensitivte storage locations\n",
    "BUFFER_DISTANCE = 500\n",
    "MAX_DIFF = [15,25,50,100]\n",
    "print(const.sampleNumber)\n",
    "print(const.MATCH_FOLDER)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deda7b7",
   "metadata": {},
   "source": [
    "## Part 2: helper functions used by the main script ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6be96",
   "metadata": {},
   "source": [
    "### combine multiple csv files of canidate matches into a single pandas dataframe  ###\n",
    "**INPUTS:**\n",
    " - matchFolder (str) - absolute filepath to folder containing csv files to combine\n",
    "<br>\n",
    "\n",
    "**OUTPUTS:**<br>\n",
    " - pandas dataframe containing the comprehensie set of candidate matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5810788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineMatches(matchFolder):\n",
    "    filesToCombine = glob.glob(matchFolder + \"/*.csv\")\n",
    "    print(\"found %i match files to combine\" %(len(filesToCombine)))\n",
    "    \n",
    "    li = []\n",
    "    index = 0\n",
    "    for filename in filesToCombine:\n",
    "        tempDF = ps.read_csv(filename)\n",
    "        li.append(tempDF)\n",
    "        if(index %10000 == 0):\n",
    "            print(\"completed loading %i files\" %(index))\n",
    "        index+=1\n",
    "    combinedData = ps.concat(li)    \n",
    "\n",
    "    # here is where you define the variable names\n",
    "    newDF = ps.DataFrame({\n",
    "        'exp_id':combinedData['exp_id'],\n",
    "        'ctrl_id':combinedData['ctrl_id'],\n",
    "        'ctrl_year':combinedData['ctrl_year'],\n",
    "        'ctrl_cat':combinedData['ctrl_cat'],\n",
    "        'exp_year':combinedData['exp_year'],\n",
    "        'exp_cat':combinedData['exp_cat'],\n",
    "        'exp_dist':combinedData['exp_dist'],\n",
    "        'ctrl_dist':combinedData['ctrl_dist'],\n",
    "        'cat_diff':combinedData['cat_diff'],\n",
    "        'dist_diff':combinedData['dist_diff'],\n",
    "        'year_diff':combinedData['year_diff'],\n",
    "        'abs_dist':combinedData['abs_dist'],\n",
    "        'abs_year':combinedData['abs_year']\n",
    "    })\n",
    "    \n",
    "    # rename variables based on whether the residence is an exposed or control\n",
    "    newDF['uniqueid'] = newDF['exp_id']\n",
    "    valsWithDist = ps.read_csv(const.WIND_METRICS)\n",
    "    mergeVals = valsWithDist[['uniqueid','NEAR_DIST']]\n",
    "    newDF = newDF.merge(mergeVals,how='inner',on='uniqueid')\n",
    "    newDF = newDF[newDF['NEAR_DIST']>=0]\n",
    "    newDF['near_dist_exp'] = newDF['NEAR_DIST']\n",
    "    newDF = newDF.drop(['NEAR_DIST'],axis=1)\n",
    "    newDF['uniqueid'] = newDF['ctrl_id']\n",
    "    newDF = newDF.merge(mergeVals,how='inner',on='uniqueid')\n",
    "    newDF = newDF[newDF['NEAR_DIST']>=0]\n",
    "    newDF['near_dist_ctrl'] = newDF['NEAR_DIST']\n",
    "    newDF = newDF.drop(['NEAR_DIST','uniqueid'],axis=1)\n",
    "    newDF ['near_dist_diff'] = newDF['near_dist_exp'] - newDF['near_dist_ctrl']\n",
    "    newDF['gradient_match_score'] = newDF['near_dist_diff'].abs()\n",
    "    \n",
    "    # create a score that quantifies how good the matches are, and sort matches by the derived score\n",
    "    newDF['match_score'] = newDF['abs_dist'] + newDF['gradient_match_score'] + newDF['abs_year']*10\n",
    "    newDF.sort_values(by=['match_score'],inplace=True)\n",
    "    \n",
    "    print(\"number of records in comprehensive match dataframe: %i \" %(newDF.count()[0]))\n",
    "    return(newDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fbbe5e",
   "metadata": {},
   "source": [
    "### select best exposed/control matches that sample controls without replacement ###\n",
    "**INPUTS:**\n",
    " - candidateMatches (pandas DataFrame) - dataset of candidate matches\n",
    "<br>\n",
    "\n",
    "**OUTPUTS:**<br>\n",
    " - pandas dataframe containing matches with best match scores that without using repeat controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOriginalMatches(candidateMatches):\n",
    "    \n",
    "    candidateMatches.sort_values(by=['match_score'],inplace=True)\n",
    "    # iterate through candidate matches, selecting best score and removing other scores using the same control\n",
    "    remainingMatches = deepcopy(candidateMatches)\n",
    "    firstSet = True\n",
    "    while(remainingMatches.count()[0]>0):\n",
    "        curMatch = remainingMatches.groupby('exp_id').head(1)\n",
    "        print(curMatch.count()[0])\n",
    "        curMatch = curMatch.groupby('ctrl_id').head(1)\n",
    "        print(curMatch.count()[0])\n",
    "        #curMatch = remainingMatches.iloc[0]\n",
    "        if(firstSet):\n",
    "            chosenMatches = curMatch\n",
    "            firstSet = False\n",
    "        else:\n",
    "            chosenMatches = ps.concat([curMatch,chosenMatches],ignore_index=False)#ps.concat([chosenMatches,curMatch])\n",
    "        remainingMatches = remainingMatches[~remainingMatches['exp_id'].isin(list(set(curMatch['exp_id'])))]\n",
    "        remainingMatches = remainingMatches[~remainingMatches['ctrl_id'].isin(list(set(curMatch['ctrl_id'])))]\n",
    "        numProcessed = len(chosenMatches)\n",
    "        if(numProcessed%250==0):\n",
    "            print(\"num procesed: %i, num remaining: %i\" %(numProcessed,remainingMatches.count()[0]))\n",
    "    \n",
    "    # convert list of original matches into a pandas DataFrame\n",
    "    origMatches = ps.DataFrame({\n",
    "    'exp_id':list(chosenMatches['exp_id']),\n",
    "    'ctrl_id':list(chosenMatches['ctrl_id']),\n",
    "    'ctrl_year':list(chosenMatches['ctrl_year']),\n",
    "    'ctrl_cat':list(chosenMatches['ctrl_cat']),\n",
    "    'exp_year':list(chosenMatches['exp_year']),\n",
    "    'exp_cat':list(chosenMatches['exp_cat']),\n",
    "    'exp_dist':list(chosenMatches['exp_dist']),\n",
    "    'ctrl_dist':list(chosenMatches['ctrl_dist']),\n",
    "    'cat_diff':list(chosenMatches['cat_diff']),\n",
    "    'dist_diff':list(chosenMatches['dist_diff']),\n",
    "    'year_diff':list(chosenMatches['year_diff']),\n",
    "    'abs_dist':list(chosenMatches['abs_dist']),\n",
    "    'abs_year':list(chosenMatches['abs_year']),\n",
    "    'gradient_score':list(chosenMatches['gradient_match_score']),\n",
    "    'match_score':list(chosenMatches['match_score']),\n",
    "    'near_dist_exp':list(chosenMatches['near_dist_exp']),\n",
    "    'near_dist_ctrl':list(chosenMatches['near_dist_ctrl'])\n",
    "    })\n",
    "    \n",
    "    origMatches['orig_ctrl'] = [1 for x in range(origMatches.count()[0])]\n",
    "    origMatches['n_matches'] = [0 for x in range(origMatches.count()[0])]\n",
    "    \n",
    "    print(\"created %i original matches \" %(origMatches.count()[0]))\n",
    "    return(origMatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a495854",
   "metadata": {},
   "source": [
    "### select best exposed/control matches that sample controls with replacement ###\n",
    "**INPUTS:**\n",
    " - unmatchedCandidates (pandas DataFrame) - dataset of candidate matches\n",
    " - resample (string) - whether to resample exposed or ctrl to get multiple matches\n",
    " - prevMatchPenalty (int) - adjust match score to reduce match quality for repeated sampling\n",
    " - maxAllowedMatches (int) - maximum number of times a control id can be repeatedly sampled\n",
    "<br>\n",
    "\n",
    "**OUTPUTS:**<br>\n",
    " - pandas dataframe containing matches with best match scores using repeat controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd579bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnoriginalMatches(unmatchedCandidates,resample='exp_id',prevMatchPenalty=10,maxAllowedMatches=4):\n",
    "    \n",
    "    # define whether exposed or controls are resampled to get multiple matches\n",
    "    if resample == 'ctrl_id':\n",
    "        uniqueSample = 'exp_id'\n",
    "    else:\n",
    "        uniqueSample = 'ctrl_id'\n",
    "    remainingMatches = deepcopy(unmatchedCandidates)\n",
    " \n",
    "    \n",
    "    # iterate through candidate matches, selecting best match and updating scores with new penalty\n",
    "    firstSet = True\n",
    "    while(remainingMatches.count()[0]>0):\n",
    "        \n",
    "        # get the best matches, using each record only once\n",
    "        curMatch = remainingMatches.groupby('exp_id').head(1)\n",
    "        curMatch = curMatch.groupby('ctrl_id').head(1)\n",
    "        \n",
    "        # if this is the first match create a new dataset.  Otherwise append to previous matches\n",
    "        if(firstSet):\n",
    "            chosenMatches = curMatch\n",
    "            firstSet = False\n",
    "        else:\n",
    "            chosenMatches = ps.concat([curMatch,chosenMatches],ignore_index=True)\n",
    "            \n",
    "        # update match scores to add the penalty for previous matches\n",
    "        newUnMatch = list(set(curMatch[uniqueSample]))\n",
    "        remainingMatches = remainingMatches[~remainingMatches[uniqueSample].isin(newUnMatch)]\n",
    "        newReMatch = list(set(curMatch[resample]))\n",
    "        addVals = (remainingMatches[resample].isin(newReMatch))\n",
    "        remainingMatches['n_matches'] += addVals\n",
    "        remainingMatches['match_score'] += addVals*prevMatchPenalty\n",
    "        \n",
    "        # remove all remaining matches with controls that have been used maxAllowedMatches or more times\n",
    "        remainingMatches = remainingMatches[remainingMatches['n_matches']<maxAllowedMatches]\n",
    "        remainingMatches.sort_values(by=['match_score'],inplace=True)\n",
    "        numProcessed = len(chosenMatches)\n",
    "        if(numProcessed%500==0):\n",
    "            print(\"num procesed: %i, num remaining: %i\" %(numProcessed,remainingMatches.count()[0]))\n",
    "    \n",
    "    # create new dataframe from matches\n",
    "    secondMatches = ps.DataFrame({\n",
    "        'ctrl_id':list(chosenMatches['ctrl_id']),\n",
    "        'exp_id':list(chosenMatches['exp_id']),\n",
    "        'ctrl_year':list(chosenMatches['ctrl_year']),\n",
    "        'ctrl_cat':list(chosenMatches['ctrl_cat']),\n",
    "        'exp_year':list(chosenMatches['exp_year']),\n",
    "        'exp_cat':list(chosenMatches['exp_cat']),\n",
    "        'exp_dist':list(chosenMatches['exp_dist']),\n",
    "        'ctrl_dist':list(chosenMatches['ctrl_dist']),\n",
    "        'cat_diff':list(chosenMatches['cat_diff']),\n",
    "        'dist_diff':list(chosenMatches['dist_diff']),\n",
    "        'year_diff':list(chosenMatches['year_diff']),\n",
    "        'abs_dist':list(chosenMatches['abs_dist']),\n",
    "        'abs_year':list(chosenMatches['abs_year']),\n",
    "        'match_score':list(chosenMatches['match_score']),\n",
    "        'gradient_score':list(chosenMatches['gradient_match_score']),\n",
    "        'n_matches':list(chosenMatches['n_matches']),\n",
    "        'near_dist_exp':list(chosenMatches['near_dist_exp']),\n",
    "        'near_dist_ctrl':list(chosenMatches['near_dist_ctrl'])\n",
    "    })\n",
    "    \n",
    "    secondMatches['orig_match_id'] = 1*(secondMatches['n_matches']==0)\n",
    "    print(\"found %i matches that used previously matched controls \" %(secondMatches.count()[0]))\n",
    "    \n",
    "    return(secondMatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7612fd4",
   "metadata": {},
   "source": [
    "### select best exposed/control matches, first using without control replacement and then for unmatched exposed try sampling controls with replacement ###\n",
    "**INPUTS:**\n",
    " - candidateMatches (pandas DataFrame) - dataset of candidate matches\n",
    " - outputFilepath (str) absolute filepath where selected matches will be stored\n",
    " - maxDistance (int) - maximum allowable difference in distance to road between exposed and matched control\n",
    " - numMatches (int) - maximum number of times any maternal residence can be matched to another\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestMatchesWithinDistance2(candidateMatches,outputFilepath,maxDistance=100,numMatches=4):\n",
    "    \n",
    "    # restrict candidate matches based on distance and year inclusion criteria\n",
    "    screenedCandidates = candidateMatches[candidateMatches['abs_dist']<maxDistance]\n",
    "    screenedCandidates = screenedCandidates[screenedCandidates['gradient_match_score']<maxDistance]\n",
    "    screenedCandidates = screenedCandidates[screenedCandidates['abs_year']<4]\n",
    "    print(\"%i candidate matches were found within %i distance\" %(screenedCandidates.count()[0],maxDistance))\n",
    "    \n",
    "    # get original matches (each residence can only be matched once)\n",
    "    origMatches = getOriginalMatches(screenedCandidates)\n",
    "    if(numMatches>1):\n",
    "        print(\"matching more than once\")\n",
    "        \n",
    "        # identify exposed that have not yet been matches and find best matches using previously matched controls\n",
    "        unmatchedCandidates = screenedCandidates[~screenedCandidates['exp_id'].isin(list(origMatches['exp_id']))]\n",
    "    \n",
    "        unmatchedCandidates['match_score'] += 10\n",
    "        unmatchedCandidates['n_matches'] = [1 for i in range(unmatchedCandidates.count()[0])]\n",
    "    \n",
    "        unorigMatches = getUnoriginalMatches(unmatchedCandidates,'ctrl_id',maxAllowedMatches=numMatches-1)\n",
    "        allMatches = ps.concat([origMatches,unorigMatches])\n",
    "    else:\n",
    "        print(\"only selecting original matches\")\n",
    "        allMatches = origMatches\n",
    "    \n",
    "    print(\"found %i matches total for max distance %i\" %(allMatches.count()[0],maxDistance))\n",
    "    allMatches.to_csv(outputFilepath,index=False)\n",
    "    print(\"saved all matches to designated filepath (see constants file for absolute filepath)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50f116",
   "metadata": {},
   "source": [
    "## Part 3: main script ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3e462",
   "metadata": {},
   "source": [
    "### load match data and vital statistics ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load matches \n",
    "candidateMatches = combineMatches(const.MATCH_FOLDER)\n",
    "\n",
    "# load the most up to date cohort records\n",
    "vitalStats = ps.read_csv(const.VITAL_STATS_FILEPATH)\n",
    "vitalStatsIds = list(set(vitalStats['uniqueid']))\n",
    "print(\"%i unique records found in vital stats file\" %(len(vitalStatsIds)))\n",
    "\n",
    "# remove records not included with the latest cohort inclusion criteria\n",
    "candidateMatches = candidateMatches[candidateMatches['exp_id'].isin(vitalStatsIds)]\n",
    "candidateMatches = candidateMatches[candidateMatches['ctrl_id'].isin(vitalStatsIds)]\n",
    "print(\"%i candidate matches left after screening with vital stats\" %(candidateMatches.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f3fae",
   "metadata": {},
   "source": [
    "### create a copy of match and vital statistics data restricted to 37 to 42 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for analyzing term birth weight and low term birth weight, restrict matches to those where the exposed and control both have\n",
    "# estimated gestational ages between 37 and 42 weeks\n",
    "vitalStats_37_42 = vitalStats[vitalStats['b_es_ges']<=42]\n",
    "vitalStats_37_42 = vitalStats_37_42[vitalStats_37_42['b_es_ges']>=37]\n",
    "vitalStats_37_42IDs = list(set(vitalStats_37_42['uniqueid']))\n",
    "print(\"%i unique records found in vital stats file\" %(len(vitalStats_37_42)))\n",
    "candidateMatches_37_42 = candidateMatches[candidateMatches['exp_id'].isin(vitalStats_37_42IDs)]\n",
    "candidateMatches_37_42 = candidateMatches_37_42[candidateMatches_37_42['ctrl_id'].isin(vitalStats_37_42IDs)]\n",
    "print(\"%i candidate matches left after restricting to 37-42 weeks\" %(candidateMatches_37_42.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914db0e7",
   "metadata": {},
   "source": [
    "### find best matches for all match distances and save results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "for maxDistance in [15,25,50,100]:\n",
    "    for numMatches in [1,10]:\n",
    "        outputFilepath = const.SELECTED_MATCH_FOLDER +  \"selected_matches_all_\" + str(numMatches) + \"_\" + str(maxDistance) + \".csv\"\n",
    "        if not(os.path.exists(outputFilepath)):\n",
    "                getBestMatchesWithinDistance2(candidateMatches,outputFilepath,maxDistance,numMatches)\n",
    "        outputFilepath = const.SELECTED_MATCH_FOLDER  +  \"selected_matches_37to42_\" + str(numMatches) + \"_\" + str(maxDistance) + \".csv\"\n",
    "        if not(os.path.exists(outputFilepath)):\n",
    "                getBestMatchesWithinDistance2(candidateMatches_37_42,outputFilepath,maxDistance,numMatches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
